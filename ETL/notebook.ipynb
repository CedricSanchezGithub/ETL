{
 "cells": [
  {
   "cell_type": "code",
   "id": "1b486e632a50335c",
   "metadata": {},
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyspark.sql import DataFrame, Row, SparkSession\n",
    "from pyspark.sql.functions import rand, when, col"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f4a35d03e99e2815",
   "metadata": {},
   "source": [
    "image = \"ressource/image/train\"\n",
    "augmented_image_folder = \"ressource/image/augmented_train\"\n",
    "\n",
    "db_url = \"jdbc:mysql://localhost:3306/wildlens\"\n",
    "db_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "}\n",
    "mysql_driver_path = os.path.abspath(\"installation/mysql-connector-j-9.1.0.jar\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8dbc99ee988fb08a",
   "metadata": {},
   "source": [
    "# Initialisation de SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"WildLens ETL - MSPR 24-25\")\n",
    "    .config(\"spark.jars\", mysql_driver_path)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Spark initialis√© avec le driver MySQL :\", mysql_driver_path)\n",
    "print(\"üîó Driver charg√© :\", spark.sparkContext.getConf().get(\"spark.jars\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ceb123a4ec31ef2",
   "metadata": {},
   "source": [
    "try:\n",
    "    df_tables = (\n",
    "        spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", db_url)\n",
    "        .option(\"dbtable\", \"information_schema.tables\")\n",
    "        .option(\"user\", \"root\")\n",
    "        .option(\"password\", \"root\")\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "    df_tables.filter(df_tables[\"TABLE_SCHEMA\"] == \"wildlens\").select(\n",
    "        \"TABLE_NAME\"\n",
    "    ).show()\n",
    "\n",
    "    print(\"‚úÖ Connexion √† MySQL r√©ussie et tables list√©es avec succ√®s !\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur de connexion √† MySQL : {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c91af73f42eed839",
   "metadata": {},
   "source": [
    "# Gestion des m√©tadonn√©es des esp√®ces\n",
    "\n",
    " Dans un premier temps, nous scannons les dossiers disponibles afin d'en faire un dataframe et r√©utiliser ces informations.\n",
    " Puis nous r√©cup√©rons les m√©tadonn√©es depuis l'API Mistral gr√¢ce √† un prompt optimis√© (optimisation du grounding, du prompt engineering)\n",
    " un sleep de 3s a √©t√© ajout√© afin d'√©viter de trop spam l'API\n",
    " -- transf√©r√© dans un fichier √† part --"
   ]
  },
  {
   "cell_type": "code",
   "id": "6e0bfa1214a1b566",
   "metadata": {},
   "source": [
    "folder_all_animals = [\n",
    "    d\n",
    "    for d in os.listdir(\"ressource/image/train\")\n",
    "    if os.path.isdir(os.path.join(\"ressource/image/train\", d))\n",
    "]\n",
    "df_all_animals = pd.DataFrame(folder_all_animals, columns=[\"Nom du dossier\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e6ec049174921c",
   "metadata": {},
   "source": [
    "# Gestion des images\n",
    "Dans un premier temps, nous allons faire une premi√®re analyse des images: leurs nombre par esp√®ces (donc, par dossier), leurs tailles moyenne, leurs poid moyen, etc..."
   ]
  },
  {
   "cell_type": "code",
   "id": "8d591c85933d0423",
   "metadata": {},
   "source": [
    "# D√©finition des chemins des datasets\n",
    "image = \"ressource/image/train\"\n",
    "\n",
    "\n",
    "# Fonction pour r√©cup√©rer les infos des images d'un dossier (en g√©rant les dossiers absents)\n",
    "def get_image_info(folder_path):\n",
    "    if not os.path.exists(folder_path):  # üìå V√©rifie si le dossier existe\n",
    "        return 0, None, None  # ‚ö†Ô∏è Si absent ‚Üí 0 images et tailles nulles\n",
    "\n",
    "    image_files = [\n",
    "        f for f in os.listdir(folder_path) if f.lower().endswith((\"png\", \"jpg\", \"jpeg\"))\n",
    "    ]\n",
    "    num_images = len(image_files)\n",
    "\n",
    "    if num_images == 0:\n",
    "        return num_images, None, None  # Aucun fichier image\n",
    "\n",
    "    widths, heights = [], []\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                widths.append(img.width)\n",
    "                heights.append(img.height)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec l'image {img_file}: {e}\")\n",
    "\n",
    "    avg_width = sum(widths) / len(widths) if widths else None\n",
    "    avg_height = sum(heights) / len(heights) if heights else None\n",
    "\n",
    "    return num_images, avg_width, avg_height\n",
    "\n",
    "\n",
    "# Listes pour stocker les infos\n",
    "image_data = []\n",
    "\n",
    "# Parcourir chaque dossier et extraire les infos\n",
    "for folder in df_all_animals[\"Nom du dossier\"]:\n",
    "    # ‚úÇÔ∏è Images recadr√©es - entra√Ænement\n",
    "    folder_path_train = os.path.join(image, folder)\n",
    "    num_images_train, avg_width_train, avg_height_train = get_image_info(\n",
    "        folder_path_train\n",
    "    )\n",
    "    image_data.append([folder, num_images_train, avg_width_train, avg_height_train])\n",
    "\n",
    "# Cr√©ation des DataFrames\n",
    "df_image = pd.DataFrame(\n",
    "    image_data,\n",
    "    columns=[\"Nom du dossier\", \"Nombre d'images\", \"Largeur Moyenne\", \"Hauteur Moyenne\"],\n",
    ")\n",
    "\n",
    "# Affichage du DataFrame de comparaison\n",
    "display(df_image)\n",
    "\n",
    "# üìä Visualisation : Comparaison du nombre d'images par dossier\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x_labels = df_image[\"Nom du dossier\"]\n",
    "x_range = range(len(x_labels))\n",
    "\n",
    "plt.bar(x_range, df_image[\"Nombre d'images\"], width=0.3, label=\"Images\", color=\"blue\")\n",
    "\n",
    "plt.xticks([x for x in x_range], x_labels, rotation=90)  # Centrage des labels\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"Comparaison du nombre d'images par dossier\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee7bbce44f5c0285",
   "metadata": {},
   "source": [
    "# Augmentation des images\n",
    "## Data Augmentation et Transformation des Donn√©es\n",
    "La Data Augmentation est une technique utilis√©e en apprentissage automatique, notamment en vision par ordinateur et en traitement du langage naturel (NLP), pour augmenter la diversit√© des donn√©es d'entra√Ænement sans collecter de nouvelles donn√©es. Elle permet de rendre les mod√®les plus robustes et d'am√©liorer leur g√©n√©ralisation.\n",
    "\n",
    "- Calculer la Mediane du nombre des images\n",
    "- Determiner le Q3 afin que le nombre d'image finale de chaque animale se rapproche\n",
    "- Calculer le coefficient de multiplication pour chaque classe d'animaux\n",
    "- Modifier et sauvegarder les nouvelles images"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f5d64005d5fd03f",
   "metadata": {},
   "source": [
    "median_images = df_image[\"Nombre d'images\"].median()\n",
    "q3_images = df_image[\"Nombre d'images\"].quantile(0.75)\n",
    "\n",
    "print(f\"M√©diane: {median_images}, Q3: {q3_images}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44a66928c7b481ad",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "os.makedirs(augmented_image_folder, exist_ok=True)\n",
    "df_image[\"Coeff\"] = np.ceil(q3_images / df_image[\"Nombre d'images\"])\n",
    "\n",
    "augmentation = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),  # Flip horizontal : effet miroir\n",
    "        A.RandomBrightnessContrast(p=0.2),  # Modification de la luminosit√©/contraste\n",
    "        A.Rotate(limit=30, p=0.5),  # Rotation al√©atoire\n",
    "        A.GaussNoise(p=0.1),  # Ajout de bruit\n",
    "        A.Resize(256, 256),  # Redimensionnement en 256x256\n",
    "    ]\n",
    ")\n",
    "\n",
    "for index, row in df_image.iterrows():\n",
    "    if row[\"Coeff\"] < 4:\n",
    "        folder_name = row[\"Nom du dossier\"]\n",
    "        coeff = int(row[\"Coeff\"])\n",
    "\n",
    "        original_folder = os.path.join(image, folder_name)\n",
    "        augmented_folder = os.path.join(augmented_image_folder, folder_name)\n",
    "        os.makedirs(augmented_folder, exist_ok=True)\n",
    "\n",
    "        image_files = [\n",
    "            f\n",
    "            for f in os.listdir(original_folder)\n",
    "            if f.lower().endswith((\"png\", \"jpg\", \"jpeg\"))\n",
    "        ]\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(original_folder, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"‚ùå Erreur de lecture de l'image {img_file}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            for i in range(coeff):\n",
    "                augmented = augmentation(image=img)[\"image\"]\n",
    "                new_img_path = os.path.join(augmented_folder, f\"aug_{i}_{img_file}\")\n",
    "                cv2.imwrite(new_img_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print(\"‚úÖ Data Augmentation termin√©e avec succ√®s !\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5bf17ca281a9d2da",
   "metadata": {},
   "source": [
    "# Listes pour stocker les infos\n",
    "image_data_new = []\n",
    "image_new = \"ressource/image/augmented_train\"\n",
    "\n",
    "# Parcourir chaque dossier et extraire les infos\n",
    "for folder in df_all_animals[\"Nom du dossier\"]:\n",
    "    folder_path_train = os.path.join(image_new, folder)\n",
    "    num_images_train, avg_width_train, avg_height_train = get_image_info(\n",
    "        folder_path_train\n",
    "    )\n",
    "    image_data_new.append([folder, num_images_train, avg_width_train, avg_height_train])\n",
    "\n",
    "# Cr√©ation des DataFrames\n",
    "image_data_new = pd.DataFrame(\n",
    "    image_data_new,\n",
    "    columns=[\"Nom du dossier\", \"Nombre d'images\", \"Largeur Moyenne\", \"Hauteur Moyenne\"],\n",
    ")\n",
    "image_data_new[\"Coeff\"] = df_image[\"Coeff\"]\n",
    "# Affichage du DataFrame de comparaison\n",
    "display(image_data_new)\n",
    "\n",
    "# üìä Visualisation : Comparaison du nombre d'images par dossier\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x_labels = image_data_new[\"Nom du dossier\"]\n",
    "x_range = range(len(x_labels))\n",
    "\n",
    "plt.bar(\n",
    "    x_range, image_data_new[\"Nombre d'images\"], width=0.3, label=\"Images\", color=\"blue\"\n",
    ")\n",
    "\n",
    "plt.xticks([x for x in x_range], x_labels, rotation=90)  # Centrage des labels\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"Comparaison du nombre d'images par dossier\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "361b703c676963f5",
   "metadata": {},
   "source": [
    "display(image_data_new)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6c410402e8af2b3",
   "metadata": {},
   "source": [
    "## Labellisation\n",
    "Le dataframe d'images et les m√©tadata sont fusionn√©es afin que chaque image corresponde √† des m√©tadonn√©es : c'est la lab√©lisation."
   ]
  },
  {
   "cell_type": "code",
   "id": "a770a2a2eb3142b5",
   "metadata": {},
   "source": [
    "df_metadata = pd.read_csv(\"./ressource/metadata.csv\")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    image_data_new,\n",
    "    df_metadata,\n",
    "    left_on=\"Nom du dossier\",\n",
    "    right_on=\"Esp√®ce anglais\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df_merged = df_merged.drop(\n",
    "    columns=[\"Nom du dossier\", \"Largeur Moyenne\", \"Hauteur Moyenne\"]\n",
    ")\n",
    "print(df_merged)\n",
    "df_merged.to_csv(\"./ressource/data_merged.csv\", header=True)\n",
    "\n",
    "if print(df_merged[\"Esp√®ce anglais\"].isna().sum()):\n",
    "    print(\"Toutes les lignes ont trouv√©s une correspondance\")\n",
    "display(df_merged)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ed6804733aedbc5e",
   "metadata": {},
   "source": [
    "# State\n",
    "Ajout d'un state al√©atoire sur chaque image.\n",
    "\n",
    "70% de train (1)\n",
    "\n",
    "15% de test (2)\n",
    "\n",
    "15% de val (3)\n",
    "\n",
    "Ceci servira prochainement pour l'entrainement du model de machine learning\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c60defc76e7c47c7",
   "metadata": {},
   "source": [
    "df_merged_spark = spark.createDataFrame(df_merged)\n",
    "image_new = \"ressource/image/augmented_train\"\n",
    "\n",
    "df_dict = {}\n",
    "for dossier in (\n",
    "    df_merged_spark.select(\"Esp√®ce anglais\")\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    "):\n",
    "    folder_path = os.path.join(image_new, dossier)\n",
    "    if os.path.exists(folder_path):\n",
    "        df_images = spark.createDataFrame(\n",
    "            [(dossier, os.path.join(dossier, img)) for img in os.listdir(folder_path)],\n",
    "            [\"Esp√®ce anglais\", \"Chemin Relatif\"],\n",
    "        )\n",
    "        df_dict[dossier] = df_images.join(\n",
    "            df_merged_spark.select(\"Esp√®ce anglais\"), on=\"Esp√®ce anglais\"\n",
    "        )\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "for dossier, df in df_dict.items():\n",
    "    df = df.withColumn(\"rand_val\", rand())\n",
    "    df = df.withColumn(\n",
    "        \"state\",\n",
    "        when(col(\"rand_val\") <= train_ratio, 1)\n",
    "        .when(col(\"rand_val\") <= (train_ratio + val_ratio), 2)\n",
    "        .otherwise(3),\n",
    "    )\n",
    "    df_dict[dossier] = df\n",
    "    df.write.mode(\"overwrite\").parquet(f\"ressource/dataframes_parquet/{dossier}\")\n",
    "    df.write.mode(\"overwrite\").csv(f\"ressource/dataframes_csv/{dossier}\")\n",
    "    print(f\"‚úÖ State ajout√© et fichier enregistr√© pour {dossier}\")\n",
    "if df_dict:\n",
    "    df_final = reduce(DataFrame.unionAll, df_dict.values())\n",
    "    print(f\" Fusion compl√®te ! Le DataFrame final contient {df_final.count()} images.\")\n",
    "    df_final.write.mode(\"overwrite\").parquet(\"ressource/dataframes_parquet/all_images\")\n",
    "    df_final.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "        \"ressource/dataframes_csv/all_images\", header=True\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun DataFrame √† fusionner !\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c78f8882db62b04",
   "metadata": {},
   "source": [
    "df_final.printSchema()\n",
    "df_final.show(10)\n",
    "print(f\"Nombre total d'images : {df_final.count()}\")\n",
    "print(f\"Colonnes : {df_final.columns}\")\n",
    "\n",
    "df_pandas = df_final.toPandas()\n",
    "\n",
    "# Compter les occurrences des √©tats (1 = train, 2 = val, 3 = test)\n",
    "state_counts = df_pandas[\"state\"].value_counts().sort_index()\n",
    "\n",
    "# üìä Cr√©ation du graphique\n",
    "plt.figure(figsize=(8, 5))\n",
    "state_counts.plot(kind=\"bar\", color=[\"blue\", \"orange\", \"green\"])\n",
    "\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"R√©partition des images entre Train (1), Validation (2) et Test (3)\")\n",
    "plt.xticks(\n",
    "    ticks=[0, 1, 2], labels=[\"Train (1)\", \"Validation (2)\", \"Test (3)\"], rotation=0\n",
    ")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n",
    "\n",
    "# Compter le nombre d'images par esp√®ce\n",
    "species_counts = df_pandas[\"Esp√®ce anglais\"].value_counts().head(10)  # Top 10\n",
    "\n",
    "# üìä Cr√©ation du graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "species_counts.plot(kind=\"bar\", color=\"purple\")\n",
    "\n",
    "plt.xlabel(\"Esp√®ce\")\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"Top 10 des esp√®ces avec le plus d'images\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n",
    "\n",
    "# üìä 2. R√©partition des images par classe et par dataset (Histogramme group√©)\n",
    "df_final_pandas = df_final.toPandas()\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_grouped = df_final_pandas.groupby([\"Esp√®ce anglais\", \"state\"]).size().unstack()\n",
    "df_grouped.plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Nombre d'images par classe et par dataset\")\n",
    "plt.xlabel(\"Esp√®ce\")\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend([\"Train (1)\", \"Validation (2)\", \"Test (3)\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c43cb08e0b17102b",
   "metadata": {},
   "source": [
    "df_final.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfaa31d9c772f67b",
   "metadata": {},
   "source": [
    "print(\"Colonnes de df_facts :\", df_final.columns)\n",
    "print(df_final.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "787e4c49e491df6b",
   "metadata": {},
   "source": [
    "df_existing = spark.read.jdbc(\n",
    "    url=db_url, table=\"wildlens_etat\", properties=db_properties\n",
    ")\n",
    "\n",
    "if df_existing.count() == 0:\n",
    "    print(\"La table wildlens_etat est vide, insertion des donn√©es...\")\n",
    "\n",
    "    df_etat = spark.createDataFrame(\n",
    "        [\n",
    "            Row(id_etat=1, type=\"train\"),\n",
    "            Row(id_etat=2, type=\"test\"),\n",
    "            Row(id_etat=3, type=\"validation\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df_etat.write.mode(\"append\").jdbc(\n",
    "        url=db_url, table=\"wildlens_etat\", properties=db_properties\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2dce1d5168a440fd",
   "metadata": {},
   "source": [
    "metadata_path = \"ressource/data_merged.csv\"\n",
    "df_meta = spark.read.option(\"header\", True).option(\"sep\", \",\").csv(metadata_path)\n",
    "\n",
    "df_existing = spark.read.jdbc(\n",
    "    url=db_url, table=\"wildlens_facts\", properties=db_properties\n",
    ")\n",
    "\n",
    "if df_existing.count() == 0:\n",
    "    print(\"La table wildlens_facts est vide, insertion des donn√©es...\")\n",
    "\n",
    "    df_facts = df_meta.select(\n",
    "        \"Esp√®ce fran√ßais\",\n",
    "        \"Famille\",\n",
    "        \"Nom latin\",\n",
    "        \"Description\",\n",
    "        \"Population estim√©e\",\n",
    "        \"Localisation\",\n",
    "        \"Esp√®ce anglais\",\n",
    "        \"Nombre d'images\",\n",
    "        \"Coeff\",\n",
    "    ).dropDuplicates()\n",
    "\n",
    "    df_facts = (\n",
    "        df_facts.withColumnRenamed(\"Esp√®ce anglais\", \"nom_en\")\n",
    "        .withColumnRenamed(\"Population estim√©e\", \"population_estimee\")\n",
    "        .withColumnRenamed(\"Nombre d'images\", \"nombre_image\")\n",
    "        .withColumnRenamed(\"Esp√®ce fran√ßais\", \"nom_fr\")\n",
    "        .withColumnRenamed(\"Nom latin\", \"nom_latin\")\n",
    "        .withColumnRenamed(\"Famille\", \"famille\")\n",
    "        .withColumnRenamed(\"Localisation\", \"localisation\")\n",
    "        .withColumnRenamed(\"Coeff\", \"coeff_multiplication\")\n",
    "    )\n",
    "\n",
    "    df_facts.write.jdbc(\n",
    "        url=db_url, table=\"wildlens_facts\", mode=\"append\", properties=db_properties\n",
    "    )\n",
    "    print(df_facts.head(5))\n",
    "    print(\"‚úÖ Table wildlens_facts mise √† jour avec succ√®s !\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46bda1cf1805b425",
   "metadata": {},
   "source": [
    "df_existing = spark.read.jdbc(\n",
    "    url=db_url, table=\"wildlens_images\", properties=db_properties\n",
    ")\n",
    "\n",
    "if df_existing.count() == 0:\n",
    "    df_images = spark.read.jdbc(\n",
    "        url=db_url, table=\"wildlens_facts\", properties=db_properties\n",
    "    )\n",
    "    df_id_espece = df_images.select(\"id_espece\", \"nom_en\").distinct()\n",
    "\n",
    "    if \"id_espece\" in df_final.columns:\n",
    "        df_final = df_final.drop(\"id_espece\")\n",
    "\n",
    "    df_final = df_final.join(\n",
    "        df_id_espece, df_final[\"Esp√®ce anglais\"] == df_id_espece[\"nom_en\"], \"left\"\n",
    "    )\n",
    "\n",
    "    df = df_final.select(\"Chemin Relatif\", \"id_espece\", \"state\")\n",
    "    df = (\n",
    "        df.withColumnRenamed(\"Chemin Relatif\", \"image\")\n",
    "        .withColumnRenamed(\"id_espece\", \"id_espece\")\n",
    "        .withColumnRenamed(\"state\", \"id_etat\")\n",
    "    )\n",
    "\n",
    "    df.write.jdbc(\n",
    "        url=db_url, table=\"wildlens_images\", mode=\"append\", properties=db_properties\n",
    "    )\n",
    "    print(\"‚úÖ Table wildlens_images mise √† jour avec succ√®s !\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc66768b0a2e7f30",
   "metadata": {},
   "source": [
    "# Simuler df_final (reprenant la structure de ton code)\n",
    "df_final = pd.DataFrame(\n",
    "    {\n",
    "        \"Esp√®ce anglais\": [\"Lion\", \"Tigre\", \"√âl√©phant\", \"Z√®bre\"],\n",
    "        \"Chemin Relatif\": [\"img1.jpg\", \"img2.jpg\", \"img3.jpg\", \"img4.jpg\"],\n",
    "        \"state\": [1, 2, 1, 3],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Simuler df_id_espece depuis la table wildlens_facts\n",
    "df_id_espece = pd.DataFrame(\n",
    "    {\n",
    "        \"id_espece\": [101, 102, 103, 104],\n",
    "        \"nom_en\": [\"Lion\", \"Tigre\", \"√âl√©phant\", \"Z√®bre\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# V√©rifier et supprimer la colonne \"id_espece\" si elle existe d√©j√† dans df_final\n",
    "if \"id_espece\" in df_final.columns:\n",
    "    df_final = df_final.drop(columns=[\"id_espece\"])\n",
    "\n",
    "# Effectuer la jointure entre df_final et df_id_espece\n",
    "df_merged = df_final.merge(\n",
    "    df_id_espece, left_on=\"Esp√®ce anglais\", right_on=\"nom_en\", how=\"left\"\n",
    ")\n",
    "\n",
    "# S√©lectionner les colonnes pertinentes pour l'insertion en base\n",
    "df_result = df_merged[[\"Chemin Relatif\", \"id_espece\", \"state\"]].rename(\n",
    "    columns={\"Chemin Relatif\": \"image\", \"state\": \"id_etat\"}\n",
    ")\n",
    "\n",
    "# Cr√©ation de l'image de la jointure sous forme de tableau\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Affichage de df_final\n",
    "axes[0].axis(\"tight\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].table(\n",
    "    cellText=df_final.values, colLabels=df_final.columns, cellLoc=\"center\", loc=\"center\"\n",
    ")\n",
    "axes[0].set_title(\"df_final\")\n",
    "\n",
    "# Affichage de df_id_espece\n",
    "axes[1].axis(\"tight\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].table(\n",
    "    cellText=df_id_espece.values,\n",
    "    colLabels=df_id_espece.columns,\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    ")\n",
    "axes[1].set_title(\"df_id_espece (depuis wildlens_facts)\")\n",
    "\n",
    "# Affichage du DataFrame joint (df_result)\n",
    "axes[2].axis(\"tight\")\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].table(\n",
    "    cellText=df_result.values,\n",
    "    colLabels=df_result.columns,\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    ")\n",
    "axes[2].set_title(\"df_final (pr√™t pour wildlens_images)\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ddafef0d853f5800",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
