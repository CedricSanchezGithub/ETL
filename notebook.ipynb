{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.sql import DataFrame, Row, SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from pyspark.sql.functions import rand, when, col\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import lit"
   ],
   "id": "1b486e632a50335c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Variables\n",
    "# Param√®tres de connexion MySQL\n",
    "db_url = \"jdbc:mysql://localhost:3306/wildlens\"\n",
    "db_properties = { \"user\": \"root\",\n",
    "                  \"password\": \"root\",\n",
    "                  \"driver\": \"com.mysql.cj.jdbc.Driver\" }\n",
    "mysql_driver_path = os.path.abspath(\"installation/mysql-connector-j-9.1.0.jar\")"
   ],
   "id": "f4a35d03e99e2815",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialisation de SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WildLens ETL - MSPR 24-25\") \\\n",
    "    .config(\"spark.jars\", mysql_driver_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark initialis√© avec le driver MySQL :\", mysql_driver_path)\n",
    "print(\"üîó Driver charg√© :\", spark.sparkContext.getConf().get(\"spark.jars\"))\n"
   ],
   "id": "8dbc99ee988fb08a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    df_tables = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", db_url) \\\n",
    "        .option(\"dbtable\", \"information_schema.tables\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"root\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .load()\n",
    "\n",
    "    df_tables.filter(df_tables[\"TABLE_SCHEMA\"] == \"wildlens\").select(\"TABLE_NAME\").show()\n",
    "\n",
    "    print(\"‚úÖ Connexion √† MySQL r√©ussie et tables list√©es avec succ√®s !\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur de connexion √† MySQL : {e}\")"
   ],
   "id": "8ceb123a4ec31ef2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gestion des m√©tadonn√©es des esp√®ces\n",
    "\n",
    " Dans un premier temps, nous scannons les dossiers disponibles afin d'en faire un dataframe et r√©utiliser ces informations.\n",
    " Puis nous r√©cup√©rons les m√©tadonn√©es depuis l'API Mistral gr√¢ce √† un prompt optimis√© (optimisation du grounding, du prompt engineering)\n",
    " un sleep de 3s a √©t√© ajout√© afin d'√©viter de trop spam l'API\n",
    " -- transf√©r√© dans un fichier √† part --"
   ],
   "id": "c91af73f42eed839"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder_all_animals = [d for d in os.listdir(\"ressource/image/train\") if os.path.isdir(os.path.join(\"ressource/image/train\", d))]\n",
    "df_all_animals = pd.DataFrame(folder_all_animals, columns=[\"Nom du dossier\"])"
   ],
   "id": "6e0bfa1214a1b566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gestion des images\n",
    "Dans un premier temps, nous allons faire une premi√®re analyse des images: leurs nombre par esp√®ces (donc, par dossier), leurs tailles moyenne, leurs poid moyen, etc..."
   ],
   "id": "6e6ec049174921c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# D√©finition des chemins des datasets\n",
    "image = \"ressource/image/train\"\n",
    "# Fonction pour r√©cup√©rer les infos des images d'un dossier (en g√©rant les dossiers absents)\n",
    "def get_image_info(folder_path):\n",
    "    if not os.path.exists(folder_path):  # üìå V√©rifie si le dossier existe\n",
    "        return 0, None, None  # ‚ö†Ô∏è Si absent ‚Üí 0 images et tailles nulles\n",
    "\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "    num_images = len(image_files)\n",
    "\n",
    "    if num_images == 0:\n",
    "        return num_images, None, None  # Aucun fichier image\n",
    "\n",
    "    widths, heights = [], []\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                widths.append(img.width)\n",
    "                heights.append(img.height)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec l'image {img_file}: {e}\")\n",
    "\n",
    "    avg_width = sum(widths) / len(widths) if widths else None\n",
    "    avg_height = sum(heights) / len(heights) if heights else None\n",
    "\n",
    "    return num_images, avg_width, avg_height\n",
    "\n",
    "# Listes pour stocker les infos\n",
    "image_data = []\n",
    "\n",
    "# Parcourir chaque dossier et extraire les infos\n",
    "for folder in df_all_animals[\"Nom du dossier\"]:\n",
    "    # ‚úÇÔ∏è Images recadr√©es - entra√Ænement\n",
    "    folder_path_train = os.path.join(image, folder)\n",
    "    num_images_train, avg_width_train, avg_height_train = get_image_info(folder_path_train)\n",
    "    image_data.append([folder, num_images_train, avg_width_train, avg_height_train])\n",
    "\n",
    "# Cr√©ation des DataFrames\n",
    "df_image = pd.DataFrame(image_data, columns=[\"Nom du dossier\", \"Nombre d'images\", \"Largeur Moyenne\", \"Hauteur Moyenne\"])\n",
    "\n",
    "# Affichage du DataFrame de comparaison\n",
    "display(df_image)\n",
    "\n",
    "# üìä Visualisation : Comparaison du nombre d'images par dossier\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "x_labels = df_image[\"Nom du dossier\"]\n",
    "x_range = range(len(x_labels))\n",
    "\n",
    "plt.bar(x_range, df_image[\"Nombre d'images\"], width=0.3, label=\"Images\", color='blue')\n",
    "\n",
    "plt.xticks([x for x in x_range], x_labels, rotation=90)  # Centrage des labels\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"Comparaison du nombre d'images par dossier\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "8d591c85933d0423",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Augmentation des images\n",
    "## Data Augmentation et Transformation des Donn√©es\n",
    "La Data Augmentation est une technique utilis√©e en apprentissage automatique, notamment en vision par ordinateur et en traitement du langage naturel (NLP), pour augmenter la diversit√© des donn√©es d'entra√Ænement sans collecter de nouvelles donn√©es. Elle permet de rendre les mod√®les plus robustes et d'am√©liorer leur g√©n√©ralisation.\n",
    "\n",
    "- Calculer la Mediane du nombre des images\n",
    "- Determiner le Q3 afin que le nombre d'image finale de chaque animale se rapproche\n",
    "- Calculer le coefficient de multiplication pour chaque classe d'animaux\n",
    "- Modifier et sauvegarder les nouvelles images\n",
    "-"
   ],
   "id": "ee7bbce44f5c0285"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# üìÇ D√©finition du chemin des images\n",
    "image = \"ressource/image/train\"\n",
    "augmented_image_folder = \"ressource/image/augmented_train\"\n",
    "\n",
    "# üìù √âtape 1 : Calculer la m√©diane et Q3 du nombre d'images\n",
    "median_images = df_image[\"Nombre d'images\"].median()\n",
    "q3_images = df_image[\"Nombre d'images\"].quantile(0.75)\n",
    "\n",
    "print(f\"M√©diane: {median_images}, Q3: {q3_images}\")\n"
   ],
   "id": "6f5d64005d5fd03f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "# Cr√©ation du dossier de sortie s'il n'existe pas\n",
    "os.makedirs(augmented_image_folder, exist_ok=True)\n",
    "\n",
    "# D√©termination du coefficient de Data Augmentation\n",
    "df_image[\"Coeff\"] = np.ceil(q3_images / df_image[\"Nombre d'images\"])\n",
    "\n",
    "# D√©finition des transformations\n",
    "augmentation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.GaussNoise(p=0.1),\n",
    "    A.Resize(256, 256)\n",
    "])\n",
    "\n",
    "# Boucle sur chaque classe d‚Äôanimaux\n",
    "for index, row in df_image.iterrows():\n",
    "    if row[\"Coeff\"] < 4 :\n",
    "        folder_name = row[\"Nom du dossier\"]\n",
    "        coeff = int(row[\"Coeff\"])\n",
    "\n",
    "        original_folder = os.path.join(image, folder_name)\n",
    "        augmented_folder = os.path.join(augmented_image_folder, folder_name)\n",
    "        os.makedirs(augmented_folder, exist_ok=True)\n",
    "\n",
    "        image_files = [f for f in os.listdir(original_folder) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(original_folder, img_file)\n",
    "            img = cv2.imread(img_path)  # Lecture avec OpenCV (BGR)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"‚ùå Erreur de lecture de l'image {img_file}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Conversion en RGB (√©vite les probl√®mes de couleur)\n",
    "\n",
    "            for i in range(coeff):  # G√©n√©rer plusieurs images augment√©es\n",
    "                augmented = augmentation(image=img)[\"image\"]\n",
    "                new_img_path = os.path.join(augmented_folder, f\"aug_{i}_{img_file}\")\n",
    "                cv2.imwrite(new_img_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))  # Sauvegarde avec OpenCV\n",
    "\n",
    "print(\"‚úÖ Data Augmentation termin√©e avec succ√®s !\")\n"
   ],
   "id": "44a66928c7b481ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Listes pour stocker les infos\n",
    "image_data_new = []\n",
    "image_new = \"ressource/image/augmented_train\"\n",
    "\n",
    "# Parcourir chaque dossier et extraire les infos\n",
    "for folder in df_all_animals[\"Nom du dossier\"]:\n",
    "    # ‚úÇÔ∏è Images recadr√©es - entra√Ænement\n",
    "    folder_path_train = os.path.join(image_new, folder)\n",
    "    num_images_train, avg_width_train, avg_height_train = get_image_info(folder_path_train)\n",
    "    image_data_new.append([folder, num_images_train, avg_width_train, avg_height_train])\n",
    "\n",
    "# Cr√©ation des DataFrames\n",
    "image_data_new = pd.DataFrame(image_data_new, columns=[\"Nom du dossier\", \"Nombre d'images\", \"Largeur Moyenne\", \"Hauteur Moyenne\"])\n",
    "image_data_new[\"Coeff\"] = df_image[\"Coeff\"]\n",
    "# Affichage du DataFrame de comparaison\n",
    "display(image_data_new)\n",
    "\n",
    "# üìä Visualisation : Comparaison du nombre d'images par dossier\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "x_labels = image_data_new[\"Nom du dossier\"]\n",
    "x_range = range(len(x_labels))\n",
    "\n",
    "plt.bar(x_range, image_data_new[\"Nombre d'images\"], width=0.3, label=\"Images\", color='blue')\n",
    "\n",
    "plt.xticks([x for x in x_range], x_labels, rotation=90)  # Centrage des labels\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"Comparaison du nombre d'images par dossier\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5bf17ca281a9d2da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(image_data_new)",
   "id": "361b703c676963f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lab√©lisation\n",
    "Le dataframe d'images et les m√©tadata sont fusionn√©es afin que chaque image corresponde √† des m√©tadonn√©es : c'est la lab√©lisation."
   ],
   "id": "c6c410402e8af2b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_metadata = pd.read_csv(\"./ressource/metadata.csv\")\n",
    "\n",
    "df_merged = pd.merge(image_data_new, df_metadata, left_on='Nom du dossier', right_on='Esp√®ce anglais', how='left')\n",
    "df_merged = df_merged.drop(columns=[\"Nom du dossier\", \"Largeur Moyenne\", \"Hauteur Moyenne\"])\n",
    "print(df_merged)\n",
    "df_merged.to_csv(\"./ressource/data_merged.csv\", header=True)\n",
    "\n",
    "if print(df_merged['Esp√®ce anglais'].isna().sum()):\n",
    "    print(\"Toutes les lignes ont trouv√©s une correspondance\")\n",
    "display(df_merged)"
   ],
   "id": "a770a2a2eb3142b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# State\n",
    "Ajout d'un state al√©atoire sur chaque image.\n",
    "\n",
    "70% de train (1)\n",
    "\n",
    "15% de test (2)\n",
    "\n",
    "15% de val (3)\n",
    "\n",
    "Ceci servira prochainement pour l'entrainement du model de machine learning\n"
   ],
   "id": "ed6804733aedbc5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_merged_spark = spark.createDataFrame(df_merged)\n",
    "image_new = \"ressource/image/augmented_train\"\n",
    "\n",
    "df_dict = {}\n",
    "for dossier in df_merged_spark.select(\"Esp√®ce anglais\").distinct().rdd.flatMap(lambda x: x).collect():\n",
    "    folder_path = os.path.join(image_new, dossier)\n",
    "    if os.path.exists(folder_path):\n",
    "        df_images = spark.createDataFrame([(dossier, os.path.join(dossier, img)) for img in os.listdir(folder_path)],\n",
    "                                          [\"Esp√®ce anglais\", \"Chemin Relatif\"])\n",
    "        df_dict[dossier] = df_images.join(df_merged_spark.select(\"Esp√®ce anglais\"), on=\"Esp√®ce anglais\")\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "for dossier, df in df_dict.items():\n",
    "\n",
    "    df = df.withColumn(\"rand_val\", rand())\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"state\",\n",
    "        when(col(\"rand_val\") <= train_ratio, 1)\n",
    "        .when(col(\"rand_val\") <= (train_ratio + val_ratio), 2)\n",
    "        .otherwise(3)\n",
    "    )\n",
    "\n",
    "    df_dict[dossier] = df\n",
    "\n",
    "    df.write.mode(\"overwrite\").parquet(f\"ressource/dataframes_parquet/{dossier}\")\n",
    "    df.write.mode(\"overwrite\").csv(f\"ressource/dataframes_csv/{dossier}\")\n",
    "\n",
    "    print(f\"‚úÖ State ajout√© et fichier enregistr√© pour {dossier}\")\n",
    "\n",
    "if df_dict:\n",
    "    df_final = reduce(DataFrame.unionAll, df_dict.values())\n",
    "    print(f\" Fusion compl√®te ! Le DataFrame final contient {df_final.count()} images.\")\n",
    "    df_final.write.mode(\"overwrite\").parquet(\"ressource/dataframes_parquet/all_images\")\n",
    "    df_final.coalesce(1).write.mode(\"overwrite\").csv(\"ressource/dataframes_csv/all_images\", header=True)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun DataFrame √† fusionner !\")\n"
   ],
   "id": "c60defc76e7c47c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_final.printSchema()\n",
    "df_final.show(10)\n",
    "print(f\"Nombre total d'images : {df_final.count()}\")\n",
    "print(f\"Colonnes : {df_final.columns}\")\n",
    "\n",
    "df_pandas = df_final.toPandas()\n",
    "\n",
    "# Compter les occurrences des √©tats (1 = train, 2 = val, 3 = test)\n",
    "state_counts = df_pandas[\"state\"].value_counts().sort_index()\n",
    "\n",
    "# üìä Cr√©ation du graphique\n",
    "plt.figure(figsize=(8, 5))\n",
    "state_counts.plot(kind='bar', color=['blue', 'orange', 'green'])\n",
    "\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"R√©partition des images entre Train (1), Validation (2) et Test (3)\")\n",
    "plt.xticks(ticks=[0, 1, 2], labels=[\"Train (1)\", \"Validation (2)\", \"Test (3)\"], rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n",
    "\n",
    "# Compter le nombre d'images par esp√®ce\n",
    "species_counts = df_pandas[\"Esp√®ce anglais\"].value_counts().head(10)  # Top 10\n",
    "\n",
    "# üìä Cr√©ation du graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "species_counts.plot(kind='bar', color='purple')\n",
    "\n",
    "plt.xlabel(\"Esp√®ce\")\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.title(\"Top 10 des esp√®ces avec le plus d'images\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()"
   ],
   "id": "1c78f8882db62b04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Colonnes de df_facts :\", df_final.columns)\n",
    "print(df_final.describe())"
   ],
   "id": "dfaa31d9c772f67b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_existing = spark.read.jdbc(url=db_url, table=\"wildlens_etat\", properties=db_properties)\n",
    "\n",
    "if df_existing.count() == 0:\n",
    "    print(\"La table wildlens_etat est vide, insertion des donn√©es...\")\n",
    "\n",
    "    df_etat = spark.createDataFrame([\n",
    "        Row(id_etat=1, type=\"train\"),\n",
    "        Row(id_etat=2, type=\"test\"),\n",
    "        Row(id_etat=3, type=\"validation\")\n",
    "    ])\n",
    "\n",
    "    df_etat.write.mode(\"append\").jdbc(url=db_url, table=\"wildlens_etat\", properties=db_properties)"
   ],
   "id": "787e4c49e491df6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# üìå Chargement des m√©tadonn√©es avec Spark\n",
    "metadata_path = \"ressource/data_merged.csv\"\n",
    "df_meta = spark.read.option(\"header\", True).option(\"sep\", \",\").csv(metadata_path)\n",
    "\n",
    "df_existing = spark.read.jdbc(url=db_url, table=\"wildlens_facts\", properties=db_properties)\n",
    "\n",
    "if df_existing.count() == 0:\n",
    "\n",
    "    print(\"La table wildlens_facts est vide, insertion des donn√©es...\")\n",
    "\n",
    "    df_facts = df_meta.select(\n",
    "        \"Esp√®ce fran√ßais\", \"Famille\", \"Nom latin\", \"Description\", \"Population estim√©e\", \"Localisation\", \"Esp√®ce anglais\",\n",
    "        \"Nombre d'images\",\"Coeff\"\n",
    "    ).dropDuplicates()\n",
    "\n",
    "    df_facts = (df_facts.withColumnRenamed(\"Esp√®ce anglais\", \"nom_en\")\n",
    "                .withColumnRenamed(\"Population estim√©e\", \"population_estimee\")\n",
    "                .withColumnRenamed(\"Nombre d'images\", \"nombre_image\")\n",
    "                .withColumnRenamed(\"Esp√®ce fran√ßais\", \"nom_fr\")\n",
    "                .withColumnRenamed(\"Nom latin\", \"nom_latin\")\n",
    "                .withColumnRenamed(\"Famille\", \"famille\")\n",
    "                .withColumnRenamed(\"Localisation\", \"localisation\")\n",
    "                .withColumnRenamed(\"Coeff\", \"coeff_multiplication\"))\n",
    "\n",
    "    df_facts.write.jdbc(url=db_url, table=\"wildlens_facts\", mode=\"append\", properties=db_properties)\n",
    "\n",
    "    print(\"‚úÖ Table wildlens_facts mise √† jour avec succ√®s !\")"
   ],
   "id": "2dce1d5168a440fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_existing = spark.read.jdbc(url=db_url, table=\"wildlens_images\", properties=db_properties)\n",
    "\n",
    "if df_existing.count() == 0:\n",
    "    print(\"La table wildlens_images est vide, insertion des donn√©es...\")\n",
    "\n",
    "    df_images = spark.read.jdbc(url=db_url, table=\"wildlens_facts\", properties=db_properties)\n",
    "    df_id_espece = df_images.select(\"id_espece\", \"nom_en\").distinct()\n",
    "\n",
    "    if \"id_espece\" in df_final.columns:\n",
    "        df_final = df_final.drop(\"id_espece\")\n",
    "\n",
    "    # Effectuer la jointure pour r√©cup√©rer l'ID de l'esp√®ce\n",
    "    df_final = df_final.join(df_id_espece, df_final[\"Esp√®ce anglais\"] == df_id_espece[\"nom_en\"], \"left\")\n",
    "    print(df_final.show())\n",
    "# Charger les images et ajouter une colonne binaire \"image\"\n",
    "    df = df_final.select(\"Chemin Relatif\", \"id_espece\", \"state\")\n",
    "\n",
    "    print(df.show())  # Afficher les donn√©es pour v√©rifier\n",
    "\n",
    "    # Renommer les colonnes pour correspondre au sch√©ma MySQL\n",
    "    df = (df.withColumnRenamed(\"Chemin Relatif\", \"image\")\n",
    "                .withColumnRenamed(\"id_espece\", \"id_espece\")\n",
    "                .withColumnRenamed(\"state\", \"id_etat\"))\n",
    "    # Sauvegarder dans la base de donn√©es\n",
    "    df.write.jdbc(url=db_url, table=\"wildlens_images\", mode=\"append\", properties=db_properties)\n",
    "    print(\"‚úÖ Table wildlens_images mise √† jour avec succ√®s !\")\n"
   ],
   "id": "46bda1cf1805b425",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
