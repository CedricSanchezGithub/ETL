{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T14:20:09.188255Z",
     "start_time": "2025-02-08T14:20:09.184355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "from pyspark.sql import SparkSession"
   ],
   "id": "b5acbd9739558d6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "8c17148f7753f086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T14:20:09.233004Z",
     "start_time": "2025-02-08T14:20:09.230437Z"
    }
   },
   "source": [
    "# Variables\n",
    "# Paramètres de connexion MySQL\n",
    "db_url = \"jdbc:mysql://mysql-container:3306/wildlens?serverTimezone=UTC\"\n",
    "db_properties = { \"user\": \"root\", \"password\": \"root\", \"driver\": \"com.mysql.cj.jdbc.Driver\" }"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e8a7bb1efd54b46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T14:20:09.289488Z",
     "start_time": "2025-02-08T14:20:09.281771Z"
    }
   },
   "source": [
    "# Initialisation de SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WildLens ETL - MSPR 24-25\") \\\n",
    "    .config(\"spark.jars\", \"/installation/mysql-connector-j-9.1.0.jar\") \\\n",
    "    .getOrCreate()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/08 15:20:09 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "5668463f7b56240d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T14:20:09.547517Z",
     "start_time": "2025-02-08T14:20:09.332820Z"
    }
   },
   "source": [
    "# Chargement des informations sur les espèces\n",
    "species_info_path = './data/csv/infos_especes.csv'\n",
    "species_info_df = spark.read.csv(species_info_path, sep=\";\",header=True, inferSchema=True)\n",
    "species_info_df.show(5)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/08 15:20:09 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.\n",
      "25/02/08 15:20:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#248, None)) > 0)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 200.3 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 433.6 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.6 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 44 from csv at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:09 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got job 30 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ResultStage 54 (csv at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[109] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 13.5 KiB, free 433.6 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.6 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on cedric-galaxy-book.home:33281 (size: 6.4 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[109] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 30) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9637 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 54.0 (TID 30)\n",
      "25/02/08 15:20:09 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:09 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 54.0 (TID 30). 1639 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 30) in 7 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ResultStage 54 (csv at NativeMethodAccessorImpl.java:0) finished in 0.010 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 30 finished: csv at NativeMethodAccessorImpl.java:0, took 0.011592 s\n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 200.3 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.6 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 46 from csv at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:09 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got job 31 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ResultStage 55 (csv at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[115] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 27.9 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 12.9 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on cedric-galaxy-book.home:33281 (size: 12.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[115] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 31) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9637 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 55.0 (TID 31)\n",
      "25/02/08 15:20:09 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:09 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 55.0 (TID 31). 1547 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 31) in 15 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ResultStage 55 (csv at NativeMethodAccessorImpl.java:0) finished in 0.020 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 31 finished: csv at NativeMethodAccessorImpl.java:0, took 0.020772 s\n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 200.2 KiB, free 433.2 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.1 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 48 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:09 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got job 32 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ResultStage 56 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[119] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 18.0 KiB, free 433.1 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 433.1 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on cedric-galaxy-book.home:33281 (size: 8.0 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[119] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 32) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9637 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 56.0 (TID 32)\n",
      "25/02/08 15:20:09 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:09 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_44_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.6 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 56.0 (TID 32). 4104 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 32) in 23 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ResultStage 56 (showString at NativeMethodAccessorImpl.java:0) finished in 0.028 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 32 finished: showString at NativeMethodAccessorImpl.java:0, took 0.029342 s\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_46_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.6 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_45_piece0 on cedric-galaxy-book.home:33281 in memory (size: 6.4 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_43_piece0 on cedric-galaxy-book.home:33281 in memory (size: 79.3 KiB, free: 434.3 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  Espèce|         Description|           Nom latin|  Famille|              Taille|              Région|             Habitat|            Fun fact|\n",
      "+--------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  Castor|Le castor d’Europ...|   Castor canadensis|Mammifère|100 à 135 cm queu...|Europe du nord et...|Le castor d’Europ...|À l’exception des...|\n",
      "|    Chat|Le Chat sauvage4 ...|    Felis silvestris|Mammifère|46 à 51 cm sans l...|Amérique, Europe,...|                NULL|Un chat ne peut p...|\n",
      "|   Chien|Alors qu'on estim...|Canis lupus famil...|Mammifère|                NULL|     Hémisphère nord|                NULL|L'empreinte de la...|\n",
      "|  Coyote|Le coyote, égalem...|       Canis latrans|Mammifère|         70 à 120 cm|Amérique du nord,...|Le coyote vit dan...|Animal social et ...|\n",
      "|Ecureuil|L’écureuil est un...|    Sciurus vulgaris|Mammifère|          20 à 25 cm|Eurasie (Europe, ...|Animal arboricole...|L'écureuil est l’...|\n",
      "+--------+--------------------+--------------------+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_47_piece0 on cedric-galaxy-book.home:33281 in memory (size: 12.9 KiB, free: 434.3 MiB)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "d68b8e6a75d28847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T14:20:10.666212Z",
     "start_time": "2025-02-08T14:20:09.576794Z"
    }
   },
   "source": [
    "# Remplacer les valeurs manquantes par \"valeur manquante\"\n",
    "df_filled = species_info_df.fillna(\"missing value\")\n",
    "\n",
    "# Identifier les colonnes sans nom\n",
    "columns_with_name = [col for col in df_filled.columns if col.strip()]\n",
    "\n",
    "# Identifier les colonnes aberrantes (avec une seule valeur unique)\n",
    "abnormal_columns = []\n",
    "for col_name in columns_with_name:\n",
    "    unique_value_count = df_filled.select(col_name).distinct().count()\n",
    "    if unique_value_count <= 1:\n",
    "        abnormal_columns.append(col_name)\n",
    "\n",
    "# Supprimer les colonnes aberrantes\n",
    "columns_to_keep = [col for col in columns_with_name if col not in abnormal_columns]\n",
    "cleaned_df = df_filled.select(*columns_to_keep)\n",
    "\n",
    "# Afficher un aperçu\n",
    "cleaned_df.show()\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/08 15:20:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 200.2 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 50 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Registering RDD 123 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 16\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got map stage job 33 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[123] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 37.7 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[123] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 33) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 57.0 (TID 33)\n",
      "25/02/08 15:20:09 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:09 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 57.0 (TID 33). 2733 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 33) in 26 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ShuffleMapStage 57 (count at NativeMethodAccessorImpl.java:0) finished in 0.032 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:09 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:09 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Registering RDD 126 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 17\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got map stage job 34 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ShuffleMapStage 59 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[126] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 47.4 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[126] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 34) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 59.0 (TID 34)\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Getting 1 (888.0 B) non-empty blocks including 1 (888.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 59.0 (TID 34). 5606 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 34) in 16 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ShuffleMapStage 59 (count at NativeMethodAccessorImpl.java:0) finished in 0.022 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:09 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got job 35 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ResultStage 62 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[129] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 12.5 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on cedric-galaxy-book.home:33281 (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[129] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 35) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 62.0 (TID 35)\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 62.0 (TID 35). 3995 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 35) in 6 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ResultStage 62 (count at NativeMethodAccessorImpl.java:0) finished in 0.011 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 35 finished: count at NativeMethodAccessorImpl.java:0, took 0.013331 s\n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 200.2 KiB, free 433.6 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 54 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Registering RDD 133 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 18\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got map stage job 36 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ShuffleMapStage 63 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[133] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 37.7 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[133] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 36) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 63.0 (TID 36)\n",
      "25/02/08 15:20:09 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:09 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 63.0 (TID 36). 2733 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 36) in 18 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ShuffleMapStage 63 (count at NativeMethodAccessorImpl.java:0) finished in 0.024 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:09 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:09 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Registering RDD 136 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 19\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got map stage job 37 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ShuffleMapStage 65 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 47.4 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 37) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 65.0 (TID 37)\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Getting 1 (2.8 KiB) non-empty blocks including 1 (2.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_48_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 65.0 (TID 37). 5649 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_53_piece0 on cedric-galaxy-book.home:33281 in memory (size: 5.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 37) in 17 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ShuffleMapStage 65 (count at NativeMethodAccessorImpl.java:0) finished in 0.023 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:09 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_55_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_52_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_51_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_50_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Removed broadcast_49_piece0 on cedric-galaxy-book.home:33281 in memory (size: 8.0 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got job 38 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ResultStage 68 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on cedric-galaxy-book.home:33281 (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 38) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 68.0 (TID 38)\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 68.0 (TID 38). 3995 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 38) in 5 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ResultStage 68 (count at NativeMethodAccessorImpl.java:0) finished in 0.010 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 38 finished: count at NativeMethodAccessorImpl.java:0, took 0.019761 s\n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 200.2 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 58 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Registering RDD 143 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 20\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got map stage job 39 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[143] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 37.7 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[143] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 39) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 69.0 (TID 39)\n",
      "25/02/08 15:20:09 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:09 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 69.0 (TID 39). 2733 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 39) in 11 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ShuffleMapStage 69 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:09 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:09 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Registering RDD 146 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 21\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got map stage job 40 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ShuffleMapStage 71 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[146] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 47.4 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[146] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 40) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 71.0 (TID 40)\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Getting 1 (1048.0 B) non-empty blocks including 1 (1048.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 71.0 (TID 40). 5606 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 40) in 7 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ShuffleMapStage 71 (count at NativeMethodAccessorImpl.java:0) finished in 0.011 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:09 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Got job 41 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Final stage: ResultStage 74 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[149] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:09 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:09 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on cedric-galaxy-book.home:33281 (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:09 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[149] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 41) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:09 INFO Executor: Running task 0.0 in stage 74.0 (TID 41)\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:09 INFO Executor: Finished task 0.0 in stage 74.0 (TID 41). 3995 bytes result sent to driver\n",
      "25/02/08 15:20:09 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 41) in 5 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:09 INFO DAGScheduler: ResultStage 74 (count at NativeMethodAccessorImpl.java:0) finished in 0.007 s\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished\n",
      "25/02/08 15:20:09 INFO DAGScheduler: Job 41 finished: count at NativeMethodAccessorImpl.java:0, took 0.008594 s\n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:09 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 200.2 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 62 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 153 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 22\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 42 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 75 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[153] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 37.7 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[153] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 42) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 75.0 (TID 42)\n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_54_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_57_piece0 on cedric-galaxy-book.home:33281 in memory (size: 5.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 75.0 (TID 42). 2776 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_61_piece0 on cedric-galaxy-book.home:33281 in memory (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 42) in 20 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 75 (count at NativeMethodAccessorImpl.java:0) finished in 0.024 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_60_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_56_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_59_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_58_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 156 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 23\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 43 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 77 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[156] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 47.4 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 434.0 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[156] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 43) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 77.0 (TID 43)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 77.0 (TID 43). 5606 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 43) in 12 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 77 (count at NativeMethodAccessorImpl.java:0) finished in 0.019 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 44 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 80 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[159] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 12.5 KiB, free 434.0 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.0 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on cedric-galaxy-book.home:33281 (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[159] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 44) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 80.0 (TID 44)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 80.0 (TID 44). 3995 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 44) in 4 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 80 (count at NativeMethodAccessorImpl.java:0) finished in 0.008 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 44 finished: count at NativeMethodAccessorImpl.java:0, took 0.009844 s\n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 200.2 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 66 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 163 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 24\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 45 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 81 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[163] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 37.7 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[163] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 45) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 81.0 (TID 45)\n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 81.0 (TID 45). 2733 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 45) in 11 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 81 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 166 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 25\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 46 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 83 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[166] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 47.4 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[166] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 46) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 83.0 (TID 46)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (1156.0 B) non-empty blocks including 1 (1156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 83.0 (TID 46). 5606 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 46) in 6 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 83 (count at NativeMethodAccessorImpl.java:0) finished in 0.010 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 47 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 86 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[169] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on cedric-galaxy-book.home:33281 (size: 5.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[169] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 47) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 86.0 (TID 47)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 86.0 (TID 47). 3995 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 47) in 4 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 86 (count at NativeMethodAccessorImpl.java:0) finished in 0.006 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 47 finished: count at NativeMethodAccessorImpl.java:0, took 0.008146 s\n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 200.2 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_69_piece0 on cedric-galaxy-book.home:33281 in memory (size: 5.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_66_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_62_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 70 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_68_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_63_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_67_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 173 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 26\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 48 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 87 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[173] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_64_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.4 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_65_piece0 on cedric-galaxy-book.home:33281 in memory (size: 5.9 KiB, free: 434.4 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 37.7 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[173] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 48) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 87.0 (TID 48)\n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 87.0 (TID 48). 2733 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 48) in 19 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 87 (count at NativeMethodAccessorImpl.java:0) finished in 0.024 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 176 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 27\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 49 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 89 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[176] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 47.4 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 434.0 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[176] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 49) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 89.0 (TID 49)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (1227.0 B) non-empty blocks including 1 (1227.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 89.0 (TID 49). 5606 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 49) in 9 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 89 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 50 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 92 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[179] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 12.5 KiB, free 434.0 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.0 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on cedric-galaxy-book.home:33281 (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[179] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 50) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 92.0 (TID 50)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 92.0 (TID 50). 3952 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 50) in 3 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 92 (count at NativeMethodAccessorImpl.java:0) finished in 0.007 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 50 finished: count at NativeMethodAccessorImpl.java:0, took 0.009009 s\n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 200.2 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 74 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 183 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 28\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 51 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 93 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[183] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 37.7 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[183] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 51) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 93.0 (TID 51)\n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 93.0 (TID 51). 2733 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 51) in 13 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 93 (count at NativeMethodAccessorImpl.java:0) finished in 0.018 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 186 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 29\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 52 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[186] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 47.4 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[186] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 52) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 95.0 (TID 52)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (1883.0 B) non-empty blocks including 1 (1883.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 95.0 (TID 52). 5692 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_75_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 52) in 18 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 95 (count at NativeMethodAccessorImpl.java:0) finished in 0.021 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_70_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_72_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_71_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_73_piece0 on cedric-galaxy-book.home:33281 in memory (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 53 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 98 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[189] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on cedric-galaxy-book.home:33281 (size: 5.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[189] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 53) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 98.0 (TID 53)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 98.0 (TID 53). 3995 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 53) in 7 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 98 (count at NativeMethodAccessorImpl.java:0) finished in 0.020 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 53 finished: count at NativeMethodAccessorImpl.java:0, took 0.022715 s\n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 200.2 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 78 from count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 193 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 30\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 54 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 99 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[193] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 37.7 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 17.7 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on cedric-galaxy-book.home:33281 (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[193] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 54) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9626 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 99.0 (TID 54)\n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 99.0 (TID 54). 2733 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 54) in 25 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 99 (count at NativeMethodAccessorImpl.java:0) finished in 0.032 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Registering RDD 196 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 31\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got map stage job 55 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ShuffleMapStage 101 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[196] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 47.4 KiB, free 433.8 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on cedric-galaxy-book.home:33281 (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[196] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 55) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8988 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 101.0 (TID 55)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (2.6 KiB) non-empty blocks including 1 (2.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 101.0 (TID 55). 5606 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 55) in 14 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ShuffleMapStage 101 (count at NativeMethodAccessorImpl.java:0) finished in 0.022 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/02/08 15:20:10 INFO DAGScheduler: running: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: waiting: Set()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: failed: Set()\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 56 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 104 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[199] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 12.5 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on cedric-galaxy-book.home:33281 (size: 6.0 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[199] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 56) (cedric-galaxy-book.home, executor driver, partition 0, NODE_LOCAL, 8999 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 104.0 (TID 56)\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/02/08 15:20:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 104.0 (TID 56). 3995 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 56) in 7 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 104 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 104: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 56 finished: count at NativeMethodAccessorImpl.java:0, took 0.014041 s\n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 200.2 KiB, free 433.5 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      Espèce|         Description|           Nom latin|              Taille|              Région|             Habitat|            Fun fact|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      Castor|Le castor d’Europ...|   Castor canadensis|100 à 135 cm queu...|Europe du nord et...|Le castor d’Europ...|À l’exception des...|\n",
      "|        Chat|Le Chat sauvage4 ...|    Felis silvestris|46 à 51 cm sans l...|Amérique, Europe,...|       missing value|Un chat ne peut p...|\n",
      "|       Chien|Alors qu'on estim...|Canis lupus famil...|       missing value|     Hémisphère nord|       missing value|L'empreinte de la...|\n",
      "|      Coyote|Le coyote, égalem...|       Canis latrans|         70 à 120 cm|Amérique du nord,...|Le coyote vit dan...|Animal social et ...|\n",
      "|    Ecureuil|L’écureuil est un...|    Sciurus vulgaris|          20 à 25 cm|Eurasie (Europe, ...|Animal arboricole...|L'écureuil est l’...|\n",
      "|       Lapin|Le lapin de garen...|Oryctolagus cunic...|          34 à 50 cm|Europe et Afrique...|Le lapin de garen...|Le lapin de garen...|\n",
      "|        Loup|Le loup gris comm...|   Canis lupus lupus|0,90 à 1,10 m pou...|            Eurasie |Le loup gris comm...|Les loups solitai...|\n",
      "|        Lynx|Le lynx commun, a...|           Lynx lynx|         75 à 135 cm|            Eurasie |L’espèce vit dans...|L’expression « av...|\n",
      "|        Ours|L’ours brun est u...|        Ursus arctos|1,5 m à 3,5 m deb...|Amérique du Nord,...|L’ours brun vit d...|Les ours bruns pa...|\n",
      "|        Puma|Le puma, appelé é...|       Puma concolor|          1 à 2,30 m|Amérique du Nord ...|Le puma vit dans ...|Le puma est un an...|\n",
      "|         Rat|Le rat est un gen...|       Rattus rattus|11 à 28cm sans la...|        Monde entier|       missing value|L'Antarctique est...|\n",
      "|Raton laveur|Le raton laveur c...|       Procyon lotor|          40 à 80 cm|Amérique du Nord,...|Le raton laveur v...|Son surnom de « l...|\n",
      "|      Renard|Le renard roux, a...|       Vulpes vulpes|         90 à 120 cm|Europe, Afrique d...|L’espèce vit dans...|\"Les renards util...|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 82 from showString at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 57 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 105 (showString at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[203] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 20.5 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 433.5 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on cedric-galaxy-book.home:33281 (size: 8.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[203] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 57) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9637 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 105.0 (TID 57)\n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 105.0 (TID 57). 6297 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_76_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 57) in 14 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 105 (showString at NativeMethodAccessorImpl.java:0) finished in 0.017 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 57 finished: showString at NativeMethodAccessorImpl.java:0, took 0.018760 s\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_81_piece0 on cedric-galaxy-book.home:33281 in memory (size: 6.0 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_78_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_79_piece0 on cedric-galaxy-book.home:33281 in memory (size: 17.7 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_80_piece0 on cedric-galaxy-book.home:33281 in memory (size: 21.9 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_74_piece0 on cedric-galaxy-book.home:33281 in memory (size: 34.5 KiB, free: 434.4 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Removed broadcast_77_piece0 on cedric-galaxy-book.home:33281 in memory (size: 5.9 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "ea765c7833f919a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T14:20:10.912531Z",
     "start_time": "2025-02-08T14:20:10.676577Z"
    }
   },
   "source": [
    "# Sauvegarde au format CSV\n",
    "cleaned_df.write.csv(\"./output/data/nettoye.csv\", header=True, mode=\"overwrite\")\n",
    "\n",
    "# Sauvegarde au format Parquet\n",
    "cleaned_df.write.parquet(\"./output/data/nettoye.parquet\", mode=\"overwrite\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/08 15:20:10 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/02/08 15:20:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 200.2 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 84 from csv at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 58 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 106 (csv at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[207] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 220.4 KiB, free 433.7 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 433.6 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on cedric-galaxy-book.home:33281 (size: 78.8 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[207] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 58) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9637 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 106.0 (TID 58)\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/02/08 15:20:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: Saved output of task 'attempt_202502081520108179176397601807311_0106_m_000000_58' to file:/home/cedric/PycharmProjects/MSPR_ETL/ETL/output/data/nettoye.csv/_temporary/0/task_202502081520108179176397601807311_0106_m_000000\n",
      "25/02/08 15:20:10 INFO SparkHadoopMapRedUtil: attempt_202502081520108179176397601807311_0106_m_000000_58: Committed. Elapsed time: 0 ms.\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 106.0 (TID 58). 2527 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 58) in 33 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 106 (csv at NativeMethodAccessorImpl.java:0) finished in 0.047 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 58 finished: csv at NativeMethodAccessorImpl.java:0, took 0.048948 s\n",
      "25/02/08 15:20:10 INFO FileFormatWriter: Start to commit write Job 24ecdfed-a1c8-4e3e-8d65-3a508f262b50.\n",
      "25/02/08 15:20:10 INFO FileFormatWriter: Write Job 24ecdfed-a1c8-4e3e-8d65-3a508f262b50 committed. Elapsed time: 7 ms.\n",
      "25/02/08 15:20:10 INFO FileFormatWriter: Finished processing stats for write job 24ecdfed-a1c8-4e3e-8d65-3a508f262b50.\n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Pushed Filters: \n",
      "25/02/08 15:20:10 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "25/02/08 15:20:10 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/02/08 15:20:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/02/08 15:20:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 200.2 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.4 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on cedric-galaxy-book.home:33281 (size: 34.5 KiB, free: 434.2 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 86 from parquet at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "25/02/08 15:20:10 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Got job 59 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Final stage: ResultStage 107 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Missing parents: List()\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[211] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 221.5 KiB, free 433.2 MiB)\n",
      "25/02/08 15:20:10 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 433.1 MiB)\n",
      "25/02/08 15:20:10 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on cedric-galaxy-book.home:33281 (size: 79.3 KiB, free: 434.1 MiB)\n",
      "25/02/08 15:20:10 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[211] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 59) (cedric-galaxy-book.home, executor driver, partition 0, PROCESS_LOCAL, 9637 bytes) \n",
      "25/02/08 15:20:10 INFO Executor: Running task 0.0 in stage 107.0 (TID 59)\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/02/08 15:20:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "25/02/08 15:20:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "25/02/08 15:20:10 INFO CodecConfig: Compression: SNAPPY\n",
      "25/02/08 15:20:10 INFO CodecConfig: Compression: SNAPPY\n",
      "25/02/08 15:20:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "25/02/08 15:20:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"Espèce\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"Description\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"Nom latin\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"Taille\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"Région\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"Habitat\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"Fun fact\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : false,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  required binary Espèce (STRING);\n",
      "  required binary Description (STRING);\n",
      "  required binary Nom latin (STRING);\n",
      "  required binary Taille (STRING);\n",
      "  required binary Région (STRING);\n",
      "  required binary Habitat (STRING);\n",
      "  required binary Fun fact (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "25/02/08 15:20:10 INFO FileScanRDD: Reading File path: file:///home/cedric/PycharmProjects/MSPR_ETL/ETL/data/csv/infos_especes.csv, range: 0-6384, partition values: [empty row]\n",
      "25/02/08 15:20:10 INFO LineRecordReader: Found UTF-8 BOM and skipped it\n",
      "25/02/08 15:20:10 INFO FileOutputCommitter: Saved output of task 'attempt_20250208152010963452933579292125_0107_m_000000_59' to file:/home/cedric/PycharmProjects/MSPR_ETL/ETL/output/data/nettoye.parquet/_temporary/0/task_20250208152010963452933579292125_0107_m_000000\n",
      "25/02/08 15:20:10 INFO SparkHadoopMapRedUtil: attempt_20250208152010963452933579292125_0107_m_000000_59: Committed. Elapsed time: 0 ms.\n",
      "25/02/08 15:20:10 INFO Executor: Finished task 0.0 in stage 107.0 (TID 59). 2527 bytes result sent to driver\n",
      "25/02/08 15:20:10 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 59) in 41 ms on cedric-galaxy-book.home (executor driver) (1/1)\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "25/02/08 15:20:10 INFO DAGScheduler: ResultStage 107 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.067 s\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/02/08 15:20:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished\n",
      "25/02/08 15:20:10 INFO DAGScheduler: Job 59 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.068383 s\n",
      "25/02/08 15:20:10 INFO FileFormatWriter: Start to commit write Job 77ce0548-1cd6-4d02-9bd6-e3360a3417d0.\n",
      "25/02/08 15:20:10 INFO FileFormatWriter: Write Job 77ce0548-1cd6-4d02-9bd6-e3360a3417d0 committed. Elapsed time: 8 ms.\n",
      "25/02/08 15:20:10 INFO FileFormatWriter: Finished processing stats for write job 77ce0548-1cd6-4d02-9bd6-e3360a3417d0.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "aa4438a0086f2a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T14:20:10.998639Z",
     "start_time": "2025-02-08T14:20:10.924923Z"
    }
   },
   "source": [
    "# Écrire les données dans la table MySQL\n",
    "cleaned_df.write \\\n",
    "    .jdbc(url=db_url, table=\"Animaux\", mode=\"overwrite\", properties=db_properties)\n"
   ],
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o226.jdbc.\n: java.lang.ClassNotFoundException: com.mysql.cj.jdbc.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:103)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:254)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:258)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:47)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:766)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Écrire les données dans la table MySQL\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[43mcleaned_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[0;32m----> 3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjdbc\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdb_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAnimaux\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moverwrite\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproperties\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdb_properties\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MSPR_ETL/ETL/env/lib/python3.12/site-packages/pyspark/sql/readwriter.py:1984\u001B[0m, in \u001B[0;36mDataFrameWriter.jdbc\u001B[0;34m(self, url, table, mode, properties)\u001B[0m\n\u001B[1;32m   1982\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m properties:\n\u001B[1;32m   1983\u001B[0m     jprop\u001B[38;5;241m.\u001B[39msetProperty(k, properties[k])\n\u001B[0;32m-> 1984\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjdbc\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjprop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MSPR_ETL/ETL/env/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/MSPR_ETL/ETL/env/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    181\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
      "File \u001B[0;32m~/PycharmProjects/MSPR_ETL/ETL/env/lib/python3.12/site-packages/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
      "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o226.jdbc.\n: java.lang.ClassNotFoundException: com.mysql.cj.jdbc.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:103)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:254)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:258)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:47)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:766)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
